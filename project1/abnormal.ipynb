{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f47294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Autoencoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, RepeatVector\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. 데이터 로드 및 전처리\n",
    "# ---------------------------------------------------------\n",
    "df = pd.read_csv(\"../data/USD_KRW.csv\")\n",
    "df = df.loc[df['date'] >= '1997.12.16', ['date', 'close']]\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# 수익률 계산\n",
    "df['return'] = df['close'].shift() / df['close'].shift(5) - 1\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. 시계열 윈도우 만들기 함수\n",
    "# ---------------------------------------------------------\n",
    "def create_sequences(data, window_size):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - window_size):\n",
    "        seq = data[i:i+window_size]\n",
    "        sequences.append(seq)\n",
    "    return np.array(sequences)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. 슬라이딩 윈도우 적용\n",
    "# ---------------------------------------------------------\n",
    "WINDOW_SIZE = 5\n",
    "\n",
    "# 윈도우 적용을 위해 return만 추출\n",
    "returns = df[['return']].values\n",
    "sequences = create_sequences(returns, WINDOW_SIZE)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. 학습/검증/테스트 분할\n",
    "# ---------------------------------------------------------\n",
    "dates = df.index[WINDOW_SIZE:]  # 시퀀스의 날짜는 WINDOW_SIZE 이후부터 가능\n",
    "assert len(sequences) == len(dates)\n",
    "\n",
    "train_end = pd.Timestamp(\"2018.01.01\")\n",
    "test_start = pd.Timestamp(\"2022.01.01\")\n",
    "\n",
    "# 각 세트의 인덱스 구하기\n",
    "train_idx = dates < train_end\n",
    "test_idx = dates >= test_start\n",
    "val_idx = (dates >= train_end) & (dates < test_start)\n",
    "\n",
    "# 분할\n",
    "x_train = sequences[train_idx]\n",
    "x_val = sequences[val_idx]\n",
    "x_test = sequences[test_idx]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. 정규화 (train 기준으로 fit)\n",
    "# ---------------------------------------------------------\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 2D로 reshape 후 정규화\n",
    "x_train_2d = x_train.reshape(-1, WINDOW_SIZE)\n",
    "x_val_2d = x_val.reshape(-1, WINDOW_SIZE)\n",
    "x_test_2d = x_test.reshape(-1, WINDOW_SIZE)\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train_2d).reshape(-1, WINDOW_SIZE, 1)\n",
    "x_val_scaled = scaler.transform(x_val_2d).reshape(-1, WINDOW_SIZE, 1)\n",
    "x_test_scaled = scaler.transform(x_test_2d).reshape(-1, WINDOW_SIZE, 1)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 6. LSTM Autoencoder 정의\n",
    "# ---------------------------------------------------------\n",
    "LATENT_DIM = 16\n",
    "\n",
    "input_layer = Input(shape=(WINDOW_SIZE, 1))\n",
    "encoded = LSTM(LATENT_DIM, activation='relu', return_sequences=False)(input_layer)\n",
    "decoded = RepeatVector(WINDOW_SIZE)(encoded)\n",
    "decoded = LSTM(1, activation='linear', return_sequences=True)(decoded)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 7. 모델 학습\n",
    "# ---------------------------------------------------------\n",
    "history = autoencoder.fit(\n",
    "    x_train_scaled, x_train_scaled,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(x_val_scaled, x_val_scaled),\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 8. 테스트 데이터 재구성 오차 계산\n",
    "# ---------------------------------------------------------\n",
    "x_test_pred = autoencoder.predict(x_test_scaled)\n",
    "mse = np.mean(np.power(x_test_scaled - x_test_pred, 2), axis=(1, 2))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 9. 이상 탐지 (Threshold 자동화: IQR 방식 예시)\n",
    "# ---------------------------------------------------------\n",
    "q1 = np.percentile(mse, 25)\n",
    "q3 = np.percentile(mse, 75)\n",
    "iqr = q3 - q1\n",
    "threshold = q3 + 1.5 * iqr\n",
    "\n",
    "# 이상 탐지\n",
    "anomalies = mse > threshold\n",
    "anomaly_dates = dates[test_idx][anomalies]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 10. 시각화\n",
    "# ---------------------------------------------------------\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "mse_series = pd.Series(mse, index=dates[test_idx])\n",
    "\n",
    "# 환율 시계열에서 테스트 구간만 추출\n",
    "price_series = df.loc[dates[test_idx], 'close']\n",
    "\n",
    "# 이상치 시점에 해당하는 환율 값\n",
    "anomaly_prices = price_series.loc[anomaly_dates]\n",
    "\n",
    "# 그래프 출력\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(price_series, label='Exchange Rate', color='blue')\n",
    "plt.scatter(anomaly_dates, anomaly_prices, color='red', marker='x', label='Anomaly')\n",
    "plt.title(\"Exchange Rate with Anomalies Detected by LSTM Autoencoder\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Exchange Rate\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551718cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolation Forest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- 데이터 및 전처리 ---\n",
    "# df: 날짜 인덱스 포함 DataFrame, data: 특징 컬럼만 있는 DataFrame\n",
    "df = pd.read_csv('../data/USD_KRW.csv')\n",
    "df = df.loc[df['date'] >= '1997.12.16', : ]\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "data = df.copy()\n",
    "\n",
    "X = data.values  # (samples, features)\n",
    "dates = data.index\n",
    "\n",
    "# -------------------------\n",
    "# 3. 트렌드 제거 (환율에 대해)\n",
    "# -------------------------\n",
    "rolling_window = 20\n",
    "data['close_detrended'] = data['close'] - data['close'].rolling(window=rolling_window, min_periods=1).mean()\n",
    "\n",
    "# -------------------------\n",
    "# 4. 학습/테스트 분할\n",
    "# -------------------------\n",
    "test_start = pd.Timestamp(\"2022.01.01\")\n",
    "train_data = data.loc[data.index < test_start]\n",
    "test_data = data.loc[data.index >= test_start]\n",
    "\n",
    "# -------------------------\n",
    "# 5. 특징 선택 및 스케일링\n",
    "# -------------------------\n",
    "features = data.columns.drop('close')  # '종가'는 예측 대상이라 제외 (또는 포함해도 됨)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train_data[features])\n",
    "X_test = scaler.transform(test_data[features])\n",
    "\n",
    "# -------------------------\n",
    "# 6. Isolation Forest 훈련\n",
    "# -------------------------\n",
    "iso_forest = IsolationForest(contamination=0.02, random_state=42)\n",
    "iso_forest.fit(X_train)\n",
    "\n",
    "# 예측 (1: 정상, -1: 이상)\n",
    "y_pred = iso_forest.predict(X_test)\n",
    "anomalies = y_pred == -1\n",
    "\n",
    "# -------------------------\n",
    "# 7. 시각화\n",
    "# -------------------------\n",
    "test_dates = test_data.index\n",
    "price_series = test_data['close']\n",
    "anomaly_dates = test_dates[anomalies]\n",
    "anomaly_prices = price_series.loc[anomaly_dates]\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(test_dates, price_series, label='Exchange Rate', color='blue')\n",
    "plt.scatter(anomaly_dates, anomaly_prices, color='red', marker='x', label='Isolation Forest Anomaly')\n",
    "plt.title(\"Isolation Forest Anomaly Detection on Exchange Rate (Detrended)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Exchange Rate\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57570f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Class SVM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "# --- 데이터 및 전처리 ---\n",
    "# df: 날짜 인덱스 포함 DataFrame, data: 특징 컬럼만 있는 DataFrame\n",
    "df = pd.read_csv('../data/USD_KRW.csv')\n",
    "df = df.loc[df['날짜'] >= '1997.12.16', : ]\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Trend removal: 5-day moving average\n",
    "df_trend = df['close'].rolling(window=5, min_periods=1, center=True).mean()\n",
    "df_detrended = df.copy()\n",
    "df_detrended['close'] = data['close'] - df_trend\n",
    "\n",
    "# Scale all features\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(df_detrended)\n",
    "\n",
    "# Train One-Class SVM\n",
    "svm = OneClassSVM(nu=0.05, kernel='rbf', gamma='scale')\n",
    "svm.fit(data_scaled)\n",
    "\n",
    "# Predict\n",
    "pred = svm.predict(data_scaled)\n",
    "anomalies = pred == -1\n",
    "anomaly_dates = df.index[anomalies]\n",
    "anomaly_prices = df.loc[anomalies, 'close']\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(df.index, df['close'], label='Exchange Rate')\n",
    "plt.scatter(anomaly_dates, anomaly_prices, color='red', marker='x', label='One-Class SVM Anomaly')\n",
    "plt.title(\"One-Class SVM Anomaly Detection on Exchange Rate\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Exchange Rate\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06673897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate Z-score 기반 이상 탐지 파이프라인\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from scipy.stats import zscore\n",
    "import seaborn as sns\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv('/content/drive/MyDrive/프로젝트/일일환율.csv')\n",
    "df['날짜'] = pd.to_datetime(df['날짜'])\n",
    "df.set_index('날짜', inplace=True)\n",
    "\n",
    "# 변동률(로그 수익률) 계산\n",
    "df['return'] = np.log(df['종가']).diff(-1)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Z-score 계산\n",
    "df['z_score'] = zscore(df['return'])\n",
    "\n",
    "# ✅ Threshold 자동 설정 (IQR 방식)\n",
    "q1 = df['z_score'].quantile(0.25)\n",
    "q3 = df['z_score'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "upper = q3 + 1.5 * iqr\n",
    "lower = q1 - 1.5 * iqr\n",
    "\n",
    "# 이상치 판단\n",
    "df['anomaly'] = ((df['z_score'] > upper) | (df['z_score'] < lower)).astype(int)\n",
    "\n",
    "# ✅ 라벨 생성 (실제 라벨이 있다면 이 부분 대체 가능)\n",
    "# 수익률이 ±1.5% 이상이면 이상치로 간주\n",
    "threshold_label = 0.015\n",
    "df['label'] = (np.abs(df['return']) > threshold_label).astype(int)\n",
    "\n",
    "# ✅ 평가 지표 계산\n",
    "accuracy = accuracy_score(df['label'], df['anomaly'])\n",
    "precision = precision_score(df['label'], df['anomaly'])\n",
    "recall = recall_score(df['label'], df['anomaly'])\n",
    "f1 = f1_score(df['label'], df['anomaly'])\n",
    "\n",
    "print(\"📊 accuracy:\", round(accuracy, 3))\n",
    "print(\"📊 Precision:\", round(precision, 3))\n",
    "print(\"📊 Recall:\", round(recall, 3))\n",
    "print(\"📊 F1 Score:\", round(f1, 3))\n",
    "\n",
    "# Confusion matrix\n",
    "sns.heatmap(confusion_matrix(df['label'], df['anomaly']), annot=True, fmt='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# ✅ 시각화\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(df.index, df['종가'], label='Exchange Rate')\n",
    "plt.scatter(df.index[df['anomaly'] == 1], df['종가'][df['anomaly'] == 1], color='red', marker='x', label='Detected Anomaly')\n",
    "plt.title(\"📈 Z-score 기반 환율 이상 탐지 결과\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Exchange Rate\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f9a140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-Score 기반 예측\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "# === 파라미터 ===\n",
    "window_size = 20      # 과거 며칠 데이터를 input으로 사용할지\n",
    "future_window = 5     # 향후 며칠 중 이상치 확인\n",
    "z_thresh = 1.5       # 이상치 기준\n",
    "\n",
    "# === 데이터 로딩 ===\n",
    "df = pd.read_csv('../data/독립변수.csv')\n",
    "\n",
    "# === 기본 피처 ===\n",
    "df['return'] = df['종가'].pct_change()\n",
    "df['zscore'] = (df['종가'] - df['종가'].rolling(20).mean()) / df['종가'].rolling(20).std()\n",
    "\n",
    "# === RSI 계산 함수 ===\n",
    "def compute_rsi(series, period=14):\n",
    "    delta = series.diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    avg_gain = gain.rolling(period).mean()\n",
    "    avg_loss = loss.rolling(period).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "# === 향후 이상치 여부 타겟 생성 ===\n",
    "def label_future_outliers(z_scores, window, threshold):\n",
    "    labels = []\n",
    "    for i in range(len(z_scores)):\n",
    "        future_window = z_scores[i+1:i+1+window]\n",
    "        if future_window.isna().any() or len(future_window) < window:\n",
    "            labels.append(np.nan)\n",
    "        else:\n",
    "            labels.append(int((future_window.abs() > threshold).any()))\n",
    "    return labels\n",
    "\n",
    "df['is_outlier_future'] = label_future_outliers(df['zscore'], future_window, z_thresh)\n",
    "\n",
    "# === 추가 피처들 ===\n",
    "df['rolling_mean_5'] = df['종가'].rolling(5).mean()\n",
    "df['rolling_std_5'] = df['종가'].rolling(5).std()\n",
    "df['ema_5'] = df['종가'].ewm(span=5).mean()\n",
    "df['bollinger_upper'] = df['rolling_mean_5'] + 2 * df['rolling_std_5']\n",
    "df['bollinger_lower'] = df['rolling_mean_5'] - 2 * df['rolling_std_5']\n",
    "df['zscore_return'] = (df['return'] - df['return'].rolling(30).mean()) / df['return'].rolling(30).std()\n",
    "df['momentum_5'] = df['종가'] - df['종가'].shift(5)\n",
    "df['rsi_14'] = compute_rsi(df['종가'], 14)\n",
    "\n",
    "# === Lag 피처 ===\n",
    "for i in range(1, window_size + 1):\n",
    "    df[f'lag_{i}'] = df['종가'].shift(i)\n",
    "    df[f'return_lag_{i}'] = df['return'].shift(i)\n",
    "\n",
    "features = df.columns[1 : ]\n",
    "\n",
    "\n",
    "# === 학습용 데이터 준비 ===\n",
    "df_model = df.dropna(axis=0)\n",
    "X = df_model[features].drop('is_outlier_future', axis=1)\n",
    "y = df_model['is_outlier_future']\n",
    "\n",
    "# === Train/Test Split ===\n",
    "X_train, X_test, y_train, y_test = X[ : int(len(X) * 0.7)], X[int(len(X) * 0.7) : ], y[ : int(len(X) * 0.7)], y[int(len(X) * 0.7) : ]\n",
    "\n",
    "# === 클래스 불균형 보정 ===\n",
    "pos_weight = (len(y_train) - sum(y_train)) / sum(y_train)\n",
    "\n",
    "# === XGBoost 모델 ===\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    scale_pos_weight=pos_weight,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# === 평가 ===\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# === 피처 중요도 출력 (선택 사항) ===\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "feature_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=feature_importances.sort_values(ascending=False).head(15), y=feature_importances.sort_values(ascending=False).head(15).index)\n",
    "plt.title(\"Top 15 Feature Importances\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
